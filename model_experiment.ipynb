{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', None)        \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns can have NaN value, so should overview the columns themselves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()[train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSSubClass\n",
    "\n",
    "This is stored as a number, but behaves as a category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MSSubClass'] = train['MSSubClass'].astype('object')\n",
    "test['MSSubClass'] = test['MSSubClass'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LotFrontage\n",
    "\n",
    "The NaN values here mostly mean incomplete data, so it will be filled with the median (because it is continuous data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LotFrontage_median = train['LotFrontage'].median()\n",
    "train.loc[train['LotFrontage'].isna(), 'LotFrontage'] = LotFrontage_median\n",
    "test.loc[test['LotFrontage'].isna(), 'LotFrontage'] = LotFrontage_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MasVnrType\n",
    "\n",
    "NaN here means that it does not exist, so MasVnrArea should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['MasVnrType'].isna(), 'MasVnrArea'] = 0\n",
    "test.loc[test['MasVnrType'].isna(), 'MasVnrArea'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electric\n",
    "\n",
    "NaN here likely means that is was not documented, so it will be set to the most common one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_electrical = train['Electrical'].mode()[0]\n",
    "train.loc[train['Electrical'].isna(), 'Electrical'] = most_common_electrical\n",
    "test.loc[test['Electrical'].isna(), 'Electrical'] = most_common_electrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GarageYrBlt\n",
    "\n",
    "When a house does not have a garage, the year for it is NaN. Giving all of these values some year value would be wrong, so I decided to put these years into bins, where the NaNs will all go inside the same bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 1900, 1920, 1940, 1960, 1980, 2000, 2020]\n",
    "labels = ['None', '1900-1919', '1920-1939', '1940-1959', '1960-1979', '1980-1999', '2000-2019']\n",
    "\n",
    "train['GarageYrBltInt'] = pd.cut(train['GarageYrBlt'].fillna(0), bins=bins, labels=labels, right=False).astype('object')\n",
    "test['GarageYrBltInt'] = pd.cut(test['GarageYrBlt'].fillna(0), bins=bins, labels=labels, right=False).astype('object')\n",
    "\n",
    "train.drop(columns=['GarageYrBlt'], inplace=True)\n",
    "test.drop(columns=['GarageYrBlt'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Columns\n",
    "\n",
    "The rest of the columns where it is NaN is actually a valid category, so I will change them to 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('None', inplace=True)\n",
    "test.fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()[train.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns(df):\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    num_cols = df.select_dtypes(exclude=['object']).columns\n",
    "    \n",
    "    print(f\"Categorical columns: {len(cat_cols)}\")\n",
    "    print(cat_cols)\n",
    "    print(f\"Numerical columns: {len(num_cols)}\")\n",
    "    print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = train.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_ref = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, cat_cols):\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df, cat_cols):\n",
    "    encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(df, cat_cols, target_col, df_ref=None):\n",
    "    if df_ref is None:\n",
    "        df_ref = df\n",
    "    for col in cat_cols:\n",
    "        mean = df_ref.groupby(col)[target_col].mean()\n",
    "        df[col] = df[col].map(mean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(df, cat_cols, def_ref=None):\n",
    "    if df_ref is None:\n",
    "        df_ref = df\n",
    "    for col in cat_cols:\n",
    "        freq = df_ref[col].value_counts(normalize=True)\n",
    "        df[col] = df[col].map(freq)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding(train, cat_cols, 'SalePrice')\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding(test, cat_cols, 'SalePrice', train_ref)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_columns(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_filter(df, target_col, threshold=0.8):\n",
    "    corr = df.drop(columns=[target_col]).corr().abs()\n",
    "\n",
    "    to_drop_pairs = []\n",
    "    for i in range(len(corr.columns)):\n",
    "        for j in range(i):\n",
    "            if corr.iloc[i, j] > threshold:\n",
    "                to_drop_pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "\n",
    "    print(\"Highly correlated pairs:\")\n",
    "    for col1, col2, corr_val in to_drop_pairs:\n",
    "        print(f\"{col1} and {col2}: {corr_val}\")\n",
    "        \n",
    "    to_drop = set()\n",
    "    for col1, col2, _ in to_drop_pairs:\n",
    "        if abs(df[col1].corr(df[target_col])) > abs(df[col2].corr(df[target_col])):\n",
    "            to_drop.add(col2)\n",
    "        else:\n",
    "            to_drop.add(col1)\n",
    "            \n",
    "    to_drop = list(to_drop)\n",
    "    \n",
    "    print(f\"Columns to drop: {to_drop}\")\n",
    "    \n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe(df, target_col, n_features_to_select=10):\n",
    "    x = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    model = LinearRegression(iter=1000, random_state=42)\n",
    "    rfe = RFE(model, n_features_to_select=n_features_to_select, step=1)\n",
    "    rfe.fit(x, y)\n",
    "\n",
    "    selected_features = x.columns[rfe.support_].tolist()\n",
    "    \n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = correlation_filter(train, 'SalePrice', 0.8)\n",
    "to_stay = rfe(train, 'SalePrice', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=to_drop)\n",
    "test = test.drop(columns=to_drop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
