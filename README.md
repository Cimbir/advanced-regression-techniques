# Advanced Regression Techniques

დატასეტში არის მოცემული დახასიათება სახლებზე და მათი ფასები. პროექტის მიზანია ისეთი მოდელის შემუშავება, რომელიც ამ სახლების ფასებს მოცემული მახასიათებლებით მაქსიმალურად ზუსტად შეაფასებს

ექსპერიმენტებში ძირითადად შემდეგნაირად მაქვს მოწყობილი: თავდაპირველად ერთნაირად ვასუფთავებ დატას, ხოლო შემდეგ ხელით ვცვლი feature engineering-ისა და selection-ს ლოგიკას, რომელიც წინადგამზადებულ რეგრესიულ მოდელებზე დაეშვება განსხვავებული პარამეტრებით

## რეპოზიტორიის სტრუქტურა

`data/data_description.txt` - დატასეტის დახასიათება

`data/sample_submission.csv` - მაგალითი თუ როგორ უნდა გაიგზავნოს პასუხი

`data/test.csv` - სატესტო დატასეტი

`data/train.csv` - სატრეინინგო დატასეტი

`submissions/submission.csv` - პასუხი, რომელიც უნდა გაიგზავნოს

`graphs/` - ექსპერიმენტების დროს გრაფიკები სადაც იქმნება (მხოლოდ ასატვირთად გამოიყენება, ამიტომ აქ არ ინახება გრაფიკები)

`helper.py` - helper ფუნქციები და კლასები, რომლებიც საჭირო იყო პროექტში

`model_experiment.ipynb` - სადაც ექსპერიმენტებს ვუშვებ და ვამოწმებ

`model_inference.ipynb` - სადაც ვამოწმებ საუკეთესო მოდელს

## Feature Engineering

### კატეგორიული ცვლადებიდან რიცხვითზე გადაყვანა

აქ ვიყენებ 4 მეთოდს:

* Target Encoding - კატეგორიებს ვანაცვლებ ამ კატეგორიის დაჯგუფებით სახლის ფასის საშუალოთი
* Frequency Encoding - ნაცვლდება იმის მიხედვით თუ რამდენად ხშირად გვხვდება კატეგორია დატასეტში
* One Hot Encoding - კატეგორიის ყველა შესაძლო ვარიანტი გადის ცალკე ცვლადად
* Label Encoding - ყველა კატეგორიას ენიჭება რიცხვი დალაგების მიხედვით
* Ordinal Encoding - კატეგორიებს ენიჭება რიცხვი, რომელიც მათი მნიშვნელობის მიხედვით არის დალაგებული

ყოველ კატეგორიაზე გადავცემ სიას თუ როგორ უნდა გადავიდეს რიცხვითში. რომელიც არ იქნება სიებში, label encoding-ით გადაიყვანება

### Nan მნიშვნელობების დამუშავება + Cleaning

`MSSubClass as category` - რიცხვებით არის ჩაწერილი, მაგრამ სინამდვილეში კატეგორიებია

`Fill LotFrontage NaN with median` - აქ NaN არასრულყოფილ ინფორმაციაზე მიანიშნებს, ამიტომ შეივსება მედიანით

`MasVnrType NaN handling` - თუ NaN არის, ანუ MasVnrArea 0-ს ტოლია

`Electrical NaN handling` - თუ NaN, დიდი ალბათობით ყველაზე გავრცელებული კატეგორია იქნება, რადგან თითქმის ყველა სახლს აქვს რაიმე სახის ელექტროგაყვანილობა

`GarageYrBlt binning` - თუ არ აქვს გარაჟი, ანუ ვერც აგების წელი ექნება. ამიტომაც, უფრო სწორად ჩავთვალე წლები bin-ებში ჩამეყარა და NaN-ები ცალკე, რომ ინფორმაცია მეტ-ნაკლებად სწორად შემენარჩუნებინა

`Fill remaining NaN with 'None'` - დანარჩენი, სადაც NaN მნიშვნელობა არის, None-ებით შევავსებ კატეგორიულ ცვლადებს და 0-ებით რიცხვით ცვლადებს

## Feature Selection

აქ ვიყენებდი 2 მეთოდს: `Correlation Filter` და `RFE`

ამ 2 მიდგომისთვის მქონდა შესაბამისად 2 პარამეტრი: `corr_threshold` და `rfe_n_features`

ამ 2 ცვლადს ხელით გადავარჩევდი რათა თანდათან მივსულიყავი უკეთეს მოდელამდე

## Training

წინად მოყვანილი ყველა ეტაპის შესრულების შემდეგ დატა გადის 2 შრეში: `scaler` და `regressor`

`scaler` გადაირჩევა 5-ს შორის:

* `StandardScaler` - საშუალო დაყავს 0-ზე და ვარიაცია 1-ზე
* `MinMaxScaler` - ყველა დატა დაყავს \[0,1\] ინტერვალში 
* `RobustScaler` - ისე ასკალირებს რომ outlier-ებს ნაკლებად შეუძლიათ ცვლილება
* `Normalizer` - თითო სტრიქონი რომ ვექტორად გადავიყვანოთ, 1 ზომის უნდა იყოს
* `None` - არანაირი ცვლილება

`regressor` გადაირჩევა 3 მოდელს შორის:

* `LinearRegression` - სწავლობს წონებს ჩვეულებრივად loss ფუნქციის მინიმიზაციით
    * `Fit Intercept` - თუ True, მაშინ საწყისი წერტილი 0-ზე არ უნდა იყოს
* `Ridge` - L2 რეგულარიზაციით დიდი წონებისგან თავს ირიდებს
    * `alpha` - რეგულარიზაციის ძალა
* `Lasso` - L1 რეგულარიზაციით წონების აბსოლუტურ მნიშვნელობებს ამცირებს
    * `alpha` - რეგულარიზაციის ძალა
* `ElasticNet` - L1 და L2 რეგულარიზაციის კომბინაცია
    * `alpha` - რეგულარიზაციის ძალა
    * `l1_ratio` - L1 და L2 რეგულარიზაციის წილი

დატას სიმწირის გამო, ვიყენებ `Cross Validation`-ს, რომელიც 5-fold-ით იყოფა

შესაფასებისთვის ვიყენებ შემდეგ მეთოდებს:
* `MSE` - Mean Squared Error (ამითი ირჩევა საუკთესო მოდელი)
* `RMSE` - Root Mean Squared Error
* `MAE` - Mean Absolute Error
* `MedAE` - Median Absolute Error
* `R2` - R-squared
* `EV` - Explained Variance

ხელით რომ არ მომწეოდა ამ ყველა მოდელის გადარჩევა, გამოვიყენე `GridSearchCV`, რომელიც ყველა შესაძლო კომბინაციას გადის

### all_OHE_experiment

თავდაპირველად გავტესტე ყველა კატეგორიული ცვლადის გადაყვანა OHE-თ. ნორმალური შედეგი დადო, მაგრამ აქ საინტერესოა ყველაზე ცუდი მოდელები. სატრენინგო დატაზე საუკეთესოებისგან შედარებით ორჯერ მეტი დანაკარგიც კი არ აქვს, მაგრამ სატესტოზე უკვე სხვანაირადაა საქმე. ყველაზე ცუდ მოდელებს (კერძოდ all_OHE_8 და all_OHE_3) სადღაც 100-დან 1000-მდე უარესი შედეგები აქვთ ვიდრე საუკეთესოებს და თავისთავად, საკუთარ სატრენინგოებთან შედარებითაც. all_OHE_8-ს შემთხვევაში, MSE-ს თუ განვიხილავთ, სადღაც 4300-ჯერ უფრო დიდია ტესტებზე მაჩვენებელი ვიდრე სატრენინგო დატაზე. ცხადია ეს იმას ნიშნავს რომ მოხდა overfitting, რაც დიდი ალბათობით იმისგანაა გამოწვეული, რომ ისეთი OHE feature-ები აირჩა, რომელიც სატრენინგო დატას კარგად ეწყობოდა, მაგრამ რეალობაში სხვა დატას არც ისე კარგად

### all_label_experiment

ამ ექსპერიმენტში ყველაფერი label encoding-ით გადავიყვანე. აქ overfitting-ს მაგივრად, underfitting გამოვლინდა ყველაზე ცუდ მოდელებში, კერძოდ all_label_8. ეს იქედან გამომდინარე, რომ სატესტო და სატრენინგო დატაზე ერთნაირი შედეგები აქვს დაახლოებით, მაგრამ ორივეგან შედარებით ცუდი შედეგებია თუ გავითვალისწინებთ საუკეთესო მოდელებს. ამასთან ერთად, მოხდა ერთი ანომალიაც. all_label_5 მოდელს სატრენინგო დატაზე უარესი შედეგი ჰქონდა, ვიდრე სატესტოზე. ეს შესაძლოა იყოს იმითი გამოწვეული, რომ სატრენინგო დატაში მოხვდა ამ კონკრეტული მოდელისთვის რთულად სასწავლი დატა

### all_target_experiment + all_frequency_experiment

აქ ენკოდირება ვქენი შესაბამისად target encoding-თა და frequency encoding-ით. ორივეგან მსგავსი შედეგები დამიჯდა, სადაც ყველაზე ცუდ მოდელებს (all_frequency_5 და all_target_5) ჰქონდაც ძალიან ცუდი შეფასება სატრეინინგო და სატესტო დატაზე სხვა მოდელებთან შედარებით. დიდი ალბათობით ეს იმისი ბრალია, რომ საუკეთესო მოდელები იყენებენ ElasticNet-ს, როდესაც ყველაზე ცუდი მოდელები - LinearRegression-ს. ElasticNet L1/2 რეგულარიზაციით ახერხებს რომ ზოგი მახასიათებლის წონა შეამციროს, რაც ფაქტობრივად კიდევ ახერხებს feature selection-ს და ამის გამო უფრო კომპლექსური მოდელი უკეთ დაისწავლის. სხვა მხრივ, ჯერ-ჯერობით target encoding-თ მოხდა ყველაზე კარგად

### card_3_ohe_target_experiment + card_5_ohe_target_experiment

ამ ექსპერიმენტებში მხოლოდ 3 და 5 კარდინალობის მქოდნე კატეგორიული ცვლადი გადავიყვანე OHE-თ, დანარჩენები კი target encoding-ით. ეს კარგინალობები იმიტომ, რომ მხოლოდ მცირე რაოდენობის ახალი ცვლადი დაგენერირდეს და იქნებ ისეთი საჭირო ცვლადები აღმოჩნდეს მაგათ შორის, რომლებიც უკეთ დაახასიათებენ თითო დატას. ამან შედეგი მაინც არ გააუმჯობესა, რადგან უმეტესობა მაინც target encoding-ით აირჩა და ფაქტობრივად ცოტა სახეცვლილი all_target_experiment იყო

### ordinal_target_experiment

აქ დავაკვირდი და რამდენიმე ცვლადი ისეთი არის, რომელთაც აქვთ ლოგიკური დალაგება, მაგალითად კარგი, საშუალო და ცუდი. ამის გათვალისწინებით გამოვიყენებ ordinal encoding, რითიც შესაბამის ცვლადს შესაბამისი მნიშვნელობა მივანიჭა მისი სიმძლავდრის აღსაწერად. დანარჩენი ცვლადები კვლავ target encoding-ით გადავიყვანე. საუკეთესი მოდელის პარალელურად დავაფიქსირე, რომ ყველაზე ცუდი მოდელი არის LinearRegression(fit_intercept=False) + StandardScalara(), რომელიც სულ underfitting-ს ავლენს. მოცემული მოდელისა და დატას გათვალისწინებით, შესაძლოა იყოს outlier-ებისა და მოდელის სიმარტივის გამო. თვითონ LinearRegression შედარებით მარტივი მოდელია ისედაც და ლოგიკური იქნებოდა რომ შესაძლოა ვერ დაესწავლა დატა და რაც შეეხება outlier-ებს, არცერთი შრე არაფერს არ აკეთებს მათგან თავის დასაცავად, ამიტომ მოცემულ დატაც, სადაც რამდენიმე ასეთი შემთხვევა ფიქსირდება(რაც ექსპერიმენტების დროს აგებული grid search results გრაფიკებიდან ჩანს), ხელს უშლის მოდელს, რომ კარგად დაისწავლოს. ამ ექსპერიმენტიდან კიდევ უკეთესი მოდელი შეირჩა, რომელიც all_target_experiment-ზე უკეთესია

### ordinal_target_50_feat_experiment + ordinal_target_70_feat_experiment

ექსპერიმენტი ზუსტად იგივეა რაც წინა, მაგრამ ახლა ავირჩიე 50 და 70 საუკეთესო მახასიათებელი. თავისთავად, შედეგი გაუმჯობესდა. 50-ს შემთხვევაში საგრძნობლად, მაგრამ 70-ზე გადასვლისას უკვე მინიმალურად. როგორც ჩანს 30-50 რეინჯში ჯერ კიდევ იყო მნიშვნელოვანი მახასიათებლები, მაგრამ 50-70 გაცილებით ნაკლებად

### feature_selection_target_experiment

ზოგადად უკვე ჩანდა რომ ElasticNet + RobustScalar საკმაოდ კარგად მუშაობდა და ერთადერთი დარჩა სწორი feature-ების არჩევა, ამიტომ ამჯერად გადავარჩიე კორელაციური ფილტრით საზღვრები და RFE-თ არჩეული ცვლადების რაოდენობა. ამჯერად ordinal encoding-ს მერე ყველა სხვა ცვლადი target encoding-ით გადავიყვანე. ამ გადარჩევით გაუმჯობესდა ზოგადად MAE, მაგრამ MSE - არა. ამასთან ერთად, over/underfitting-ს შემთხვევაც არ ყოფილა. დიდი ალბათობით ზევით ნახსენები მოდელის არჩევის გამო, რომელიც აგვარებს ამ პრობლემას L1/2 რეგულარიზაციებით

## საბოლოო მოდელის შერჩევის დასაბუთება

საბოლოოდ შევარჩიე შედარებით მარტივი მოდელი რომელიც კარგად მუშაობდა: ordinal_target_42. მართალია სხვა მოდელები ტენინგისა და ტესტის დროს საკმაოდ კარგ შედეგებს აჩვენებდა, მაგრამ რეალობაში არც ისეთი კარგი მოდელები აღმოჩნდნენ, როგორიც ეს. დიდი ალბათობით დიდი რაოდენობით ცვლადს რომელიც მოიხმარდა overfit-ს აკეთებდა სატრეინინგო დატაზე და ამიტომ აღარ მუშაობდა კარგად სინამდვილეში

## MLflow Tracking

### MLflow ექსპერიმენტების ბმული

ყოველი ექსპერიმენტის გაშვებისას რეგისტრირდება საუკეთესო მოდელი მომავალში გამოსაყენებლად, ხოლო სხვა მოდელების მაჩვენებლები და პარამეტრები ლაგდება მთავარი შეფასების მიხედვით და ზედა და ქვედა 7-ს ინფორმაციას ვტვირთავ mlflow-ზე, რათა ზედმეტად არ იქნას გადატვირთული ექსპერიმენტები და ძირითადად ყველაზე საინტერესო მოდელები თავში ან ბოლოშია

გრაფიკები დავურთე შემდეგ მოდელებს:
* საუკეთესო - ordinal_target_42
* საუკეთესოები(ბოლოში) - feature_selection_target_53, ordinal_target_70_feat_67, ordinal_target_50_feat_67
* underfitted - all_frequency_5, all_target_5
* overfitted - all_OHE_8, all_OHE_3
* ანომალია - all_label_5

### ჩაწერილი მეტრიკების აღწერა

#### Parameters

* `target_encoded` - რომელი ცვლადები უნდა იყოს target encoded
* `frequency_encoded` - რომელი ცვლადები უნდა იყოს frequency encoded
* `one_hot_encoded` - რომელი ცვლადები უნდა იყოს one hot encoded
* `corr_threshold` - კორელაციის ზღვრები
* `rfe_n_features` - RFE-სთვის რამდენი ცვლადი უნდა იყოს
* `selected_features` - რომელი ცვლადები უნდა იყოს დატასეტში
* `ordinal_mapping` - რომელი ცვლადები უნდა იყოს ordinal encoded

* `scaler` - რომელი სკალერი უნდა იყოს გამოყენებული
* `regressor` - რომელი მოდელი უნდა იყოს გამოყენებული
* `regressor__fit_intercept` - თუ True, მაშინ საწყისი წერტილი 0-ზე არ უნდა იყოს
* `regressor__alpha` - რეგულარიზაციის ძალა
* `regressor__max_iter` - მაქსიმალური_iterations
* `regressor__l1_ratio` - L1 და L2 რეგულარიზაციის წილი

#### Metrics

* `MSE_tes`t - Mean Squared Error (ტესტზე)
* `RMSE_test` - Root Mean Squared Error (ტესტზე)
* `MAE_test` - Mean Absolute Error (ტესტზე)
* `MedAE_test` - Median Absolute Error (ტესტზე)
* `R2_test` - R-squared (ტესტზე)
* `EV_test` - Explained Variance (ტესტზე)
* `MSE_train` - Mean Squared Error (ტრენინგზე)
* `RMSE_train` - Root Mean Squared Error (ტრენინგზე)
* `MAE_train` - Mean Absolute Error (ტრენინგზე)
* `MedAE_train` - Median Absolute Error (ტრენინგზე)
* `R2_train` - R-squared (ტრენინგზე)
* `EV_train` - Explained Variance (ტრენინგზე)
* `Rank` - რანგი, რომელიც მოდელს აქვს მოცემულ ექსპერიმენტში

### საუკეთესო მოდელის შედეგები

logged_model = 'models:/ordinal_target_best/1' - 0.34081
